{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d41f3ed4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-23T05:01:51.591094Z",
     "iopub.status.busy": "2024-03-23T05:01:51.590744Z",
     "iopub.status.idle": "2024-03-23T05:01:54.238740Z",
     "shell.execute_reply": "2024-03-23T05:01:54.237634Z"
    },
    "papermill": {
     "duration": 2.657874,
     "end_time": "2024-03-23T05:01:54.241122",
     "exception": false,
     "start_time": "2024-03-23T05:01:51.583248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\r\n",
      "remote: Enumerating objects: 16517, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (115/115), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (99/99), done.\u001b[K\r\n",
      "remote: Total 16517 (delta 47), reused 50 (delta 16), pack-reused 16402\u001b[K\r\n",
      "Receiving objects: 100% (16517/16517), 15.17 MiB | 30.82 MiB/s, done.\r\n",
      "Resolving deltas: 100% (11304/11304), done.\r\n"
     ]
    }
   ],
   "source": [
    "# clone YOLOv5 repository\n",
    "!git clone https://github.com/ultralytics/yolov5  # clone repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfef4c13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T05:01:54.256747Z",
     "iopub.status.busy": "2024-03-23T05:01:54.256104Z",
     "iopub.status.idle": "2024-03-23T05:01:54.262435Z",
     "shell.execute_reply": "2024-03-23T05:01:54.261536Z"
    },
    "papermill": {
     "duration": 0.016125,
     "end_time": "2024-03-23T05:01:54.264420",
     "exception": false,
     "start_time": "2024-03-23T05:01:54.248295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/yolov5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0eaef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T05:01:54.279421Z",
     "iopub.status.busy": "2024-03-23T05:01:54.279132Z",
     "iopub.status.idle": "2024-03-23T05:01:55.283055Z",
     "shell.execute_reply": "2024-03-23T05:01:55.281796Z"
    },
    "papermill": {
     "duration": 1.013999,
     "end_time": "2024-03-23T05:01:55.285394",
     "exception": false,
     "start_time": "2024-03-23T05:01:54.271395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is up to date with 'origin/master'.\r\n",
      "\r\n",
      "nothing to commit, working tree clean\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0b8c8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T05:01:55.302028Z",
     "iopub.status.busy": "2024-03-23T05:01:55.301386Z",
     "iopub.status.idle": "2024-03-23T05:01:56.545188Z",
     "shell.execute_reply": "2024-03-23T05:01:56.544094Z"
    },
    "papermill": {
     "duration": 1.25483,
     "end_time": "2024-03-23T05:01:56.547670",
     "exception": false,
     "start_time": "2024-03-23T05:01:55.292840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From https://github.com/ultralytics/yolov5\r\n",
      " * branch              master     -> FETCH_HEAD\r\n",
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!git pull origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dda1da2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T05:01:56.565755Z",
     "iopub.status.busy": "2024-03-23T05:01:56.564949Z",
     "iopub.status.idle": "2024-03-23T05:02:16.455393Z",
     "shell.execute_reply": "2024-03-23T05:02:16.454330Z"
    },
    "papermill": {
     "duration": 19.901322,
     "end_time": "2024-03-23T05:02:16.457458",
     "exception": false,
     "start_time": "2024-03-23T05:01:56.556136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 2.1.2 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15102MB, multi_processor_count=40)\n"
     ]
    }
   ],
   "source": [
    "# install dependencies as necessary\n",
    "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
    "import torch\n",
    "\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "from utils.downloads import attempt_download  # to download models/datasets\n",
    "\n",
    "# clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b74899d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T05:02:16.473369Z",
     "iopub.status.busy": "2024-03-23T05:02:16.472983Z",
     "iopub.status.idle": "2024-03-23T05:02:48.294496Z",
     "shell.execute_reply": "2024-03-23T05:02:48.293444Z"
    },
    "papermill": {
     "duration": 31.831619,
     "end_time": "2024-03-23T05:02:48.296543",
     "exception": false,
     "start_time": "2024-03-23T05:02:16.464924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/yolov5\n",
      "Collecting roboflow\r\n",
      "  Downloading roboflow-1.1.25-py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Collecting certifi==2023.7.22 (from roboflow)\r\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting chardet==4.0.0 (from roboflow)\r\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Collecting cycler==0.10.0 (from roboflow)\r\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl.metadata (722 bytes)\r\n",
      "Collecting idna==2.10 (from roboflow)\r\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.4.5)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from roboflow) (3.7.4)\r\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.24.4)\r\n",
      "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\r\n",
      "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\r\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from roboflow) (9.5.0)\r\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.8.2)\r\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.0.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.31.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.16.0)\r\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.18)\r\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.66.1)\r\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (6.0.1)\r\n",
      "Requirement already satisfied: requests-toolbelt in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.10.1)\r\n",
      "Collecting python-magic (from roboflow)\r\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (1.2.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (4.47.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->roboflow) (3.3.2)\r\n",
      "Downloading roboflow-1.1.25-py3-none-any.whl (71 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading certifi-2023.7.22-py3-none-any.whl (158 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\r\n",
      "Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\r\n",
      "Installing collected packages: python-magic, opencv-python-headless, idna, cycler, chardet, certifi, roboflow\r\n",
      "  Attempting uninstall: opencv-python-headless\r\n",
      "    Found existing installation: opencv-python-headless 4.9.0.80\r\n",
      "    Uninstalling opencv-python-headless-4.9.0.80:\r\n",
      "      Successfully uninstalled opencv-python-headless-4.9.0.80\r\n",
      "  Attempting uninstall: idna\r\n",
      "    Found existing installation: idna 3.6\r\n",
      "    Uninstalling idna-3.6:\r\n",
      "      Successfully uninstalled idna-3.6\r\n",
      "  Attempting uninstall: cycler\r\n",
      "    Found existing installation: cycler 0.12.1\r\n",
      "    Uninstalling cycler-0.12.1:\r\n",
      "      Successfully uninstalled cycler-0.12.1\r\n",
      "  Attempting uninstall: certifi\r\n",
      "    Found existing installation: certifi 2023.11.17\r\n",
      "    Uninstalling certifi-2023.11.17:\r\n",
      "      Successfully uninstalled certifi-2023.11.17\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "jupyterlab 4.0.11 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.0.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.8.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-magic-0.4.27 roboflow-1.1.25\r\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in thz-4 to yolov5pytorch:: 100%|██████████| 245923/245923 [00:09<00:00, 26893.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to thz-4 in yolov5pytorch:: 100%|██████████| 25924/25924 [00:02<00:00, 8848.67it/s] \n"
     ]
    }
   ],
   "source": [
    "#follow the link below to get your download code from from Roboflow\n",
    "%cd /kaggle/working/yolov5\n",
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"THT9CtDUDzP7TPxM9CuV\")\n",
    "project = rf.workspace(\"projects-phgy0\").project(\"thz\")\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5abec9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T05:02:48.337439Z",
     "iopub.status.busy": "2024-03-23T05:02:48.337110Z",
     "iopub.status.idle": "2024-03-23T05:02:49.296992Z",
     "shell.execute_reply": "2024-03-23T05:02:49.295831Z"
    },
    "papermill": {
     "duration": 0.982948,
     "end_time": "2024-03-23T05:02:49.299654",
     "exception": false,
     "start_time": "2024-03-23T05:02:48.316706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\r\n",
      "- A4paper\r\n",
      "- AK\r\n",
      "- AK_noMagazine\r\n",
      "- M16\r\n",
      "- axe\r\n",
      "- beltholster\r\n",
      "- bottle\r\n",
      "- candyboxLid\r\n",
      "- cigaretteBox\r\n",
      "- fomka\r\n",
      "- glassjar\r\n",
      "- hammerAndSickle\r\n",
      "- handGranade\r\n",
      "- knife\r\n",
      "- meatKnife\r\n",
      "- phoneNokia\r\n",
      "- phoneXiaomi\r\n",
      "- pistol\r\n",
      "- saucepanLid\r\n",
      "- shoulderholster\r\n",
      "- tin\r\n",
      "- usbDisk\r\n",
      "nc: 22\r\n",
      "roboflow:\r\n",
      "  license: CC BY 4.0\r\n",
      "  project: thz\r\n",
      "  url: https://universe.roboflow.com/projects-phgy0/thz/dataset/4\r\n",
      "  version: 4\r\n",
      "  workspace: projects-phgy0\r\n",
      "test: ../test/images\r\n",
      "train: thz-4/train/images\r\n",
      "val: thz-4/valid/images\r\n"
     ]
    }
   ],
   "source": [
    "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
    "%cat {dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d691c4b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T05:02:49.341817Z",
     "iopub.status.busy": "2024-03-23T05:02:49.340978Z",
     "iopub.status.idle": "2024-03-23T05:02:49.350470Z",
     "shell.execute_reply": "2024-03-23T05:02:49.349564Z"
    },
    "papermill": {
     "duration": 0.032503,
     "end_time": "2024-03-23T05:02:49.352424",
     "exception": false,
     "start_time": "2024-03-23T05:02:49.319921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define number of classes based on YAML\n",
    "import yaml\n",
    "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b0a84b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T05:02:49.394172Z",
     "iopub.status.busy": "2024-03-23T05:02:49.393842Z",
     "iopub.status.idle": "2024-03-23T05:02:50.345823Z",
     "shell.execute_reply": "2024-03-23T05:02:50.344900Z"
    },
    "papermill": {
     "duration": 0.975984,
     "end_time": "2024-03-23T05:02:50.348019",
     "exception": false,
     "start_time": "2024-03-23T05:02:49.372035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# YOLOv5 🚀 by Ultralytics, AGPL-3.0 license\r\n",
      "\r\n",
      "# Parameters\r\n",
      "nc: 80 # number of classes\r\n",
      "depth_multiple: 0.67 # model depth multiple\r\n",
      "width_multiple: 0.75 # layer channel multiple\r\n",
      "anchors:\r\n",
      "  - [10, 13, 16, 30, 33, 23] # P3/8\r\n",
      "  - [30, 61, 62, 45, 59, 119] # P4/16\r\n",
      "  - [116, 90, 156, 198, 373, 326] # P5/32\r\n",
      "\r\n",
      "# YOLOv5 v6.0 backbone\r\n",
      "backbone:\r\n",
      "  # [from, number, module, args]\r\n",
      "  [\r\n",
      "    [-1, 1, Conv, [64, 6, 2, 2]], # 0-P1/2\r\n",
      "    [-1, 1, Conv, [128, 3, 2]], # 1-P2/4\r\n",
      "    [-1, 3, C3, [128]],\r\n",
      "    [-1, 1, Conv, [256, 3, 2]], # 3-P3/8\r\n",
      "    [-1, 6, C3, [256]],\r\n",
      "    [-1, 1, Conv, [512, 3, 2]], # 5-P4/16\r\n",
      "    [-1, 9, C3, [512]],\r\n",
      "    [-1, 1, Conv, [1024, 3, 2]], # 7-P5/32\r\n",
      "    [-1, 3, C3, [1024]],\r\n",
      "    [-1, 1, SPPF, [1024, 5]], # 9\r\n",
      "  ]\r\n",
      "\r\n",
      "# YOLOv5 v6.0 head\r\n",
      "head: [\r\n",
      "    [-1, 1, Conv, [512, 1, 1]],\r\n",
      "    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\r\n",
      "    [[-1, 6], 1, Concat, [1]], # cat backbone P4\r\n",
      "    [-1, 3, C3, [512, False]], # 13\r\n",
      "\r\n",
      "    [-1, 1, Conv, [256, 1, 1]],\r\n",
      "    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\r\n",
      "    [[-1, 4], 1, Concat, [1]], # cat backbone P3\r\n",
      "    [-1, 3, C3, [256, False]], # 17 (P3/8-small)\r\n",
      "\r\n",
      "    [-1, 1, Conv, [256, 3, 2]],\r\n",
      "    [[-1, 14], 1, Concat, [1]], # cat head P4\r\n",
      "    [-1, 3, C3, [512, False]], # 20 (P4/16-medium)\r\n",
      "\r\n",
      "    [-1, 1, Conv, [512, 3, 2]],\r\n",
      "    [[-1, 10], 1, Concat, [1]], # cat head P5\r\n",
      "    [-1, 3, C3, [1024, False]], # 23 (P5/32-large)\r\n",
      "\r\n",
      "    [[17, 20, 23], 1, Detect, [nc, anchors]], # Detect(P3, P4, P5)\r\n",
      "  ]\r\n"
     ]
    }
   ],
   "source": [
    "#this is the model configuration we will use for our tutorial \n",
    "%cat /kaggle/working/yolov5/models/yolov5m.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9a961b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T05:02:50.389314Z",
     "iopub.status.busy": "2024-03-23T05:02:50.388999Z",
     "iopub.status.idle": "2024-03-23T05:02:50.394413Z",
     "shell.execute_reply": "2024-03-23T05:02:50.393601Z"
    },
    "papermill": {
     "duration": 0.027973,
     "end_time": "2024-03-23T05:02:50.396246",
     "exception": false,
     "start_time": "2024-03-23T05:02:50.368273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#customize iPython writefile so we can write variables\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a770cea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T05:02:50.436563Z",
     "iopub.status.busy": "2024-03-23T05:02:50.436313Z",
     "iopub.status.idle": "2024-03-23T05:02:50.442066Z",
     "shell.execute_reply": "2024-03-23T05:02:50.441255Z"
    },
    "papermill": {
     "duration": 0.027863,
     "end_time": "2024-03-23T05:02:50.443921",
     "exception": false,
     "start_time": "2024-03-23T05:02:50.416058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writetemplate /kaggle/working/yolov5/models/custom_yolov5m.yaml\n",
    "\n",
    "# Parameters\n",
    "nc: {num_classes} # number of classes\n",
    "depth_multiple: 0.67 # model depth multiple\n",
    "width_multiple: 0.75 # layer channel multiple\n",
    "anchors:\n",
    "  - [10, 13, 16, 30, 33, 23] # P3/8\n",
    "  - [30, 61, 62, 45, 59, 119] # P4/16\n",
    "  - [116, 90, 156, 198, 373, 326] # P5/32\n",
    "\n",
    "# YOLOv5 v6.0 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [\n",
    "    [-1, 1, DWConv, [64, 6, 2, 2]], # 0-P1/2\n",
    "    [-1, 1, DWConv, [128, 3, 2]], # 1-P2/4\n",
    "    [-1, 3, C3, [128]],\n",
    "    [-1, 1, DWConv, [256, 3, 2]], # 3-P3/8\n",
    "    [-1, 6, C3, [256]],\n",
    "    [-1, 1, DWConv, [512, 3, 2]], # 5-P4/16\n",
    "    [-1, 9, C3, [512]],\n",
    "    [-1, 1, DWConv, [1024, 3, 2]], # 7-P5/32\n",
    "    [-1, 3, C3, [1024]],\n",
    "    [-1, 1, SPPF, [1024, 5]], # 9\n",
    "  ]\n",
    "\n",
    "# YOLOv5 v6.0 head\n",
    "head: [\n",
    "    [-1, 1, DWConv, [512, 1, 1]],\n",
    "    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n",
    "    [[-1, 6], 1, Concat, [1]], # cat backbone P4\n",
    "    [-1, 3, C3, [512, False]], # 13\n",
    "\n",
    "    [-1, 1, DWConv, [256, 1, 1]],\n",
    "    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n",
    "    [[-1, 4], 1, Concat, [1]], # cat backbone P3\n",
    "    [-1, 3, C3, [256, False]], # 17 (P3/8-small)\n",
    "\n",
    "    [-1, 1, DWConv, [256, 3, 2]],\n",
    "    [[-1, 14], 1, Concat, [1]], # cat head P4\n",
    "    [-1, 3, C3, [512, False]], # 20 (P4/16-medium)\n",
    "\n",
    "    [-1, 1, DWConv, [512, 3, 2]],\n",
    "    [[-1, 10], 1, Concat, [1]], # cat head P5\n",
    "    [-1, 3, C3, [1024, False]], # 23 (P5/32-large)\n",
    "\n",
    "    [[17, 20, 23], 1, Detect, [nc, anchors]], # Detect(P3, P4, P5)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0296b785",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T05:02:50.490540Z",
     "iopub.status.busy": "2024-03-23T05:02:50.490224Z",
     "iopub.status.idle": "2024-03-23T06:39:31.817182Z",
     "shell.execute_reply": "2024-03-23T06:39:31.816032Z"
    },
    "papermill": {
     "duration": 5803.00598,
     "end_time": "2024-03-23T06:39:33.469171",
     "exception": false,
     "start_time": "2024-03-23T05:02:50.463191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/yolov5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\r\n",
      "2024-03-23 05:03:03.966973: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2024-03-23 05:03:03.967123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2024-03-23 05:03:04.146711: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=./models/custom_yolov5m.yaml, data=/kaggle/working/yolov5/thz-4/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=25, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\r\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\r\n",
      "WARNING ⚠️ invalid check_version(None, >=3.3) requested, please check values.\r\n",
      "YOLOv5 🚀 v7.0-294-gdb125a20 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\r\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\r\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\r\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\r\n",
      "100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 13.5MB/s]\r\n",
      "\r\n",
      "                 from  n    params  module                                  arguments                     \r\n",
      "  0                -1  1      1824  models.common.DWConv                    [3, 48, 6, 2, 2]              \r\n",
      "  1                -1  1      1056  models.common.DWConv                    [48, 96, 3, 2]                \r\n",
      "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \r\n",
      "  3                -1  1      2112  models.common.DWConv                    [96, 192, 3, 2]               \r\n",
      "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \r\n",
      "  5                -1  1      4224  models.common.DWConv                    [192, 384, 3, 2]              \r\n",
      "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \r\n",
      "  7                -1  1      8448  models.common.DWConv                    [384, 768, 3, 2]              \r\n",
      "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \r\n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \r\n",
      " 10                -1  1      1536  models.common.DWConv                    [768, 384, 1, 1]              \r\n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \r\n",
      " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \r\n",
      " 14                -1  1       768  models.common.DWConv                    [384, 192, 1, 1]              \r\n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \r\n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \r\n",
      " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \r\n",
      " 18                -1  1      2112  models.common.DWConv                    [192, 192, 3, 2]              \r\n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \r\n",
      " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \r\n",
      " 21                -1  1      4224  models.common.DWConv                    [384, 384, 3, 2]              \r\n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \r\n",
      " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \r\n",
      " 24      [17, 20, 23]  1    109107  models.yolo.Detect                      [22, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\r\n",
      "custom_YOLOv5m summary: 291 layers, 15419379 parameters, 15419379 gradients\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\r\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\r\n",
      "WARNING ⚠️ DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\r\n",
      "See Multi-GPU Tutorial at https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training to get started.\r\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov5/thz-4/train/labels... 11512 images, 822 b\u001b[0m\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolov5/thz-4/train/labels.cache\r\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (5.6GB ram): 100%|██████████| 11512/11512 [00:23<00:00, 48\u001b[0m\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov5/thz-4/valid/labels... 722 images, 40 backgr\u001b[0m\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/yolov5/thz-4/valid/labels.cache\r\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB ram): 100%|██████████| 722/722 [00:03<00:00, 217.79it\u001b[0m\r\n",
      "\r\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.49 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\r\n",
      "Plotting labels to runs/train/yolov5s_results/labels.jpg... \r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\r\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\r\n",
      "Image sizes 416 train, 416 val\r\n",
      "Using 2 dataloader workers\r\n",
      "Logging results to \u001b[1mruns/train/yolov5s_results\u001b[0m\r\n",
      "Starting training for 25 epochs...\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       0/24      1.59G    0.09097     0.0191    0.07926         10        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682   0.000988      0.278    0.00096    0.00021\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       1/24       1.9G    0.06332    0.01572     0.0711         12        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682       0.35      0.496      0.315      0.131\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       2/24       1.9G     0.0529    0.01253    0.05487         11        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.557      0.758      0.737      0.327\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       3/24       1.9G    0.04856    0.01125    0.03884         15        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.746      0.862      0.908      0.461\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       4/24       1.9G    0.04494     0.0106    0.02757         12        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.889      0.937      0.974      0.549\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       5/24       1.9G    0.04216    0.01016    0.02175         13        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.939      0.975      0.984      0.584\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       6/24       1.9G    0.03994   0.009642    0.01829         14        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.978      0.986      0.993      0.592\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       7/24       1.9G    0.03812   0.009227    0.01554         10        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.978      0.987      0.991      0.631\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       8/24       1.9G    0.03644   0.009037    0.01407         14        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.979      0.988      0.993      0.624\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "       9/24       1.9G    0.03537   0.008884    0.01251         18        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.982      0.983      0.994      0.623\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      10/24       1.9G    0.03421   0.008675    0.01164         13        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.981      0.991       0.99      0.656\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      11/24       1.9G    0.03311   0.008464    0.01039          9        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.992      0.996      0.995      0.669\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      12/24       1.9G    0.03258   0.008423    0.01008         10        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.993      0.995      0.993       0.66\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      13/24       1.9G    0.03176   0.008117    0.00933         13        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.992      0.996      0.995      0.679\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      14/24       1.9G    0.03084   0.007997   0.008303          8        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.989      0.993      0.995      0.679\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      15/24       1.9G    0.03034   0.007898   0.007904         15        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.987      0.997      0.993      0.684\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      16/24       1.9G    0.02958   0.007912   0.007438         13        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.993          1      0.995      0.687\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      17/24       1.9G    0.02898   0.007709   0.007005         16        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682       0.99      0.997      0.993      0.698\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      18/24       1.9G    0.02836   0.007636   0.006414          7        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.996      0.993      0.995      0.677\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      19/24       1.9G    0.02766   0.007428   0.005858          9        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.991      0.996      0.995      0.699\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      20/24       1.9G    0.02717   0.007317   0.005507         11        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.992      0.996      0.995      0.708\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      21/24       1.9G    0.02659   0.007351   0.005362         12        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.994      0.995      0.995      0.709\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      22/24       1.9G    0.02597   0.007282   0.004796         17        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.994      0.996      0.995      0.716\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      23/24       1.9G    0.02549   0.007246   0.004566          9        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.992      0.999      0.995      0.718\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\r\n",
      "      24/24       1.9G    0.02483   0.007121   0.004255         18        416: 1\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.993      0.999      0.995      0.723\r\n",
      "\r\n",
      "25 epochs completed in 1.579 hours.\r\n",
      "Optimizer stripped from runs/train/yolov5s_results/weights/last.pt, 31.2MB\r\n",
      "Optimizer stripped from runs/train/yolov5s_results/weights/best.pt, 31.2MB\r\n",
      "\r\n",
      "Validating runs/train/yolov5s_results/weights/best.pt...\r\n",
      "Fusing layers... \r\n",
      "custom_YOLOv5m summary: 212 layers, 15400995 parameters, 0 gradients\r\n",
      "                 Class     Images  Instances          P          R      mAP50   \r\n",
      "                   all        722        682      0.993      0.999      0.995      0.724\r\n",
      "               A4paper        722         33      0.993          1      0.995       0.85\r\n",
      "                    AK        722         19      0.989          1      0.995      0.822\r\n",
      "         AK_noMagazine        722         33      0.992          1      0.995      0.828\r\n",
      "                   M16        722         23      0.993          1      0.995       0.65\r\n",
      "                   axe        722         41      0.993          1      0.995       0.84\r\n",
      "           beltholster        722         39      0.996          1      0.995      0.731\r\n",
      "                bottle        722         31      0.994          1      0.995      0.732\r\n",
      "           candyboxLid        722         41      0.994          1      0.995      0.825\r\n",
      "          cigaretteBox        722         35      0.994          1      0.995      0.617\r\n",
      "                 fomka        722         32      0.985          1      0.995      0.663\r\n",
      "              glassjar        722         26      0.993          1      0.995      0.649\r\n",
      "       hammerAndSickle        722         18      0.987          1      0.995       0.69\r\n",
      "           handGranade        722         35      0.995          1      0.995      0.589\r\n",
      "                 knife        722         29      0.994          1      0.995      0.752\r\n",
      "             meatKnife        722         39      0.994          1      0.995      0.753\r\n",
      "            phoneNokia        722         33      0.995          1      0.995      0.674\r\n",
      "           phoneXiaomi        722         26      0.993          1      0.995      0.678\r\n",
      "                pistol        722         43      0.996          1      0.995      0.741\r\n",
      "           saucepanLid        722         27       0.99          1      0.995      0.796\r\n",
      "       shoulderholster        722         23      0.992          1      0.995       0.79\r\n",
      "                   tin        722         34      0.996          1      0.995      0.709\r\n",
      "               usbDisk        722         22          1      0.973      0.995      0.538\r\n",
      "Results saved to \u001b[1mruns/train/yolov5s_results\u001b[0m\r\n",
      "CPU times: user 1min 42s, sys: 18.8 s, total: 2min 1s\n",
      "Wall time: 1h 36min 41s\n"
     ]
    }
   ],
   "source": [
    "### export WANDB_MODE=disabled\n",
    "# train yolov5s on custom data for 100 epochs\n",
    "# time its performance\n",
    "%cd /kaggle/working/yolov5/\n",
    "%time !python train.py --img 416 --batch 16 --epochs 25 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5m.yaml --weights '' --name yolov5s_results  --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d100d",
   "metadata": {
    "papermill": {
     "duration": 1.609783,
     "end_time": "2024-03-23T06:39:36.753991",
     "exception": false,
     "start_time": "2024-03-23T06:39:35.144208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05196bb",
   "metadata": {
    "papermill": {
     "duration": 1.657214,
     "end_time": "2024-03-23T06:39:40.086786",
     "exception": false,
     "start_time": "2024-03-23T06:39:38.429572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ff4428",
   "metadata": {
    "papermill": {
     "duration": 1.674583,
     "end_time": "2024-03-23T06:39:43.358354",
     "exception": false,
     "start_time": "2024-03-23T06:39:41.683771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c2dec",
   "metadata": {
    "papermill": {
     "duration": 1.589318,
     "end_time": "2024-03-23T06:39:46.631754",
     "exception": false,
     "start_time": "2024-03-23T06:39:45.042436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a722dc9",
   "metadata": {
    "papermill": {
     "duration": 1.640977,
     "end_time": "2024-03-23T06:39:49.918653",
     "exception": false,
     "start_time": "2024-03-23T06:39:48.277676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639f765",
   "metadata": {
    "papermill": {
     "duration": 1.649561,
     "end_time": "2024-03-23T06:39:53.158675",
     "exception": false,
     "start_time": "2024-03-23T06:39:51.509114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5887.000936,
   "end_time": "2024-03-23T06:39:55.594867",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-23T05:01:48.593931",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
