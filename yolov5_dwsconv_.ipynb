{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# clone YOLOv5 repository\n!git clone https://github.com/LakshmySanthosh/yolov5_depthwise_separable_conv  # clone repo","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-30T07:41:00.536811Z","iopub.execute_input":"2024-03-30T07:41:00.537229Z","iopub.status.idle":"2024-03-30T07:41:03.309616Z","shell.execute_reply.started":"2024-03-30T07:41:00.537195Z","shell.execute_reply":"2024-03-30T07:41:03.308394Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'yolov5_depthwise_separable_conv'...\nremote: Enumerating objects: 13210, done.\u001b[K\nremote: Counting objects: 100% (164/164), done.\u001b[K\nremote: Compressing objects: 100% (122/122), done.\u001b[K\nremote: Total 13210 (delta 82), reused 88 (delta 42), pack-reused 13046\u001b[K\nReceiving objects: 100% (13210/13210), 14.67 MiB | 24.63 MiB/s, done.\nResolving deltas: 100% (8775/8775), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/yolov5_depthwise_separable_conv/","metadata":{"execution":{"iopub.status.busy":"2024-03-30T07:41:03.311904Z","iopub.execute_input":"2024-03-30T07:41:03.312264Z","iopub.status.idle":"2024-03-30T07:41:03.320057Z","shell.execute_reply.started":"2024-03-30T07:41:03.312229Z","shell.execute_reply":"2024-03-30T07:41:03.319043Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working/yolov5_depthwise_separable_conv\n","output_type":"stream"}]},{"cell_type":"code","source":"!git status","metadata":{"execution":{"iopub.status.busy":"2024-03-30T07:41:03.321514Z","iopub.execute_input":"2024-03-30T07:41:03.321793Z","iopub.status.idle":"2024-03-30T07:41:04.289885Z","shell.execute_reply.started":"2024-03-30T07:41:03.321767Z","shell.execute_reply":"2024-03-30T07:41:04.288732Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"On branch master\nYour branch is up to date with 'origin/master'.\n\nnothing to commit, working tree clean\n","output_type":"stream"}]},{"cell_type":"code","source":"!git pull origin master","metadata":{"execution":{"iopub.status.busy":"2024-03-30T07:41:04.292887Z","iopub.execute_input":"2024-03-30T07:41:04.293217Z","iopub.status.idle":"2024-03-30T07:41:05.457872Z","shell.execute_reply.started":"2024-03-30T07:41:04.293187Z","shell.execute_reply":"2024-03-30T07:41:05.456711Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"From https://github.com/LakshmySanthosh/yolov5_depthwise_separable_conv\n * branch            master     -> FETCH_HEAD\nAlready up to date.\n","output_type":"stream"}]},{"cell_type":"code","source":"# install dependencies as necessary\n!pip install -qr requirements.txt  # install dependencies (ignore errors)\nimport torch\n\nfrom IPython.display import Image, clear_output  # to display images\nfrom utils.downloads import attempt_download  # to download models/datasets\n\n# clear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","metadata":{"execution":{"iopub.status.busy":"2024-03-30T07:41:05.461974Z","iopub.execute_input":"2024-03-30T07:41:05.462292Z","iopub.status.idle":"2024-03-30T07:41:23.591225Z","shell.execute_reply.started":"2024-03-30T07:41:05.462261Z","shell.execute_reply":"2024-03-30T07:41:23.590254Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Setup complete. Using torch 2.1.2 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15102MB, multi_processor_count=40)\n","output_type":"stream"}]},{"cell_type":"code","source":"#follow the link below to get your download code from from Roboflow\n%cd /kaggle/working/yolov5_depthwise_separable_conv\n!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"THT9CtDUDzP7TPxM9CuV\")\nproject = rf.workspace(\"projects-phgy0\").project(\"thz\")\nversion = project.version(4)\ndataset = version.download(\"yolov5\")","metadata":{"execution":{"iopub.status.busy":"2024-03-30T07:41:23.592480Z","iopub.execute_input":"2024-03-30T07:41:23.592884Z","iopub.status.idle":"2024-03-30T07:41:53.368141Z","shell.execute_reply.started":"2024-03-30T07:41:23.592857Z","shell.execute_reply":"2024-03-30T07:41:53.367275Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/working/yolov5_depthwise_separable_conv\nCollecting roboflow\n  Downloading roboflow-1.1.26-py3-none-any.whl.metadata (9.3 kB)\nCollecting certifi==2023.7.22 (from roboflow)\n  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\nCollecting chardet==4.0.0 (from roboflow)\n  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\nCollecting cycler==0.10.0 (from roboflow)\n  Downloading cycler-0.10.0-py2.py3-none-any.whl.metadata (722 bytes)\nCollecting idna==2.10 (from roboflow)\n  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.4.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from roboflow) (3.7.4)\nRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.24.4)\nCollecting opencv-python-headless==4.8.0.74 (from roboflow)\n  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\nRequirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from roboflow) (9.5.0)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.8.2)\nRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.0.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.16.0)\nRequirement already satisfied: urllib3>=1.26.6 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.18)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.66.1)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (6.0.1)\nRequirement already satisfied: requests-toolbelt in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.10.1)\nCollecting python-magic (from roboflow)\n  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (1.2.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (4.47.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->roboflow) (3.3.2)\nDownloading roboflow-1.1.26-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\nDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\nInstalling collected packages: python-magic, opencv-python-headless, idna, cycler, chardet, certifi, roboflow\n  Attempting uninstall: opencv-python-headless\n    Found existing installation: opencv-python-headless 4.9.0.80\n    Uninstalling opencv-python-headless-4.9.0.80:\n      Successfully uninstalled opencv-python-headless-4.9.0.80\n  Attempting uninstall: idna\n    Found existing installation: idna 3.6\n    Uninstalling idna-3.6:\n      Successfully uninstalled idna-3.6\n  Attempting uninstall: cycler\n    Found existing installation: cycler 0.12.1\n    Uninstalling cycler-0.12.1:\n      Successfully uninstalled cycler-0.12.1\n  Attempting uninstall: certifi\n    Found existing installation: certifi 2023.11.17\n    Uninstalling certifi-2023.11.17:\n      Successfully uninstalled certifi-2023.11.17\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab 4.0.11 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.8.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-magic-0.4.27 roboflow-1.1.26\nloading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"},{"name":"stderr","text":"Downloading Dataset Version Zip in thz-4 to yolov5pytorch:: 100%|██████████| 245923/245923 [00:07<00:00, 31331.55it/s]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"\nExtracting Dataset Version Zip to thz-4 in yolov5pytorch:: 100%|██████████| 25924/25924 [00:02<00:00, 9186.48it/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n%cat {dataset.location}/data.yaml","metadata":{"execution":{"iopub.status.busy":"2024-03-30T07:41:53.369597Z","iopub.execute_input":"2024-03-30T07:41:53.369882Z","iopub.status.idle":"2024-03-30T07:41:54.322414Z","shell.execute_reply.started":"2024-03-30T07:41:53.369858Z","shell.execute_reply":"2024-03-30T07:41:54.321547Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"names:\n- A4paper\n- AK\n- AK_noMagazine\n- M16\n- axe\n- beltholster\n- bottle\n- candyboxLid\n- cigaretteBox\n- fomka\n- glassjar\n- hammerAndSickle\n- handGranade\n- knife\n- meatKnife\n- phoneNokia\n- phoneXiaomi\n- pistol\n- saucepanLid\n- shoulderholster\n- tin\n- usbDisk\nnc: 22\nroboflow:\n  license: CC BY 4.0\n  project: thz\n  url: https://universe.roboflow.com/projects-phgy0/thz/dataset/4\n  version: 4\n  workspace: projects-phgy0\ntest: ../test/images\ntrain: thz-4/train/images\nval: thz-4/valid/images\n","output_type":"stream"}]},{"cell_type":"code","source":"# define number of classes based on YAML\nimport yaml\nwith open(dataset.location + \"/data.yaml\", 'r') as stream:\n    num_classes = str(yaml.safe_load(stream)['nc'])","metadata":{"execution":{"iopub.status.busy":"2024-03-30T07:41:54.323784Z","iopub.execute_input":"2024-03-30T07:41:54.324116Z","iopub.status.idle":"2024-03-30T07:41:54.333862Z","shell.execute_reply.started":"2024-03-30T07:41:54.324071Z","shell.execute_reply":"2024-03-30T07:41:54.333119Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#this is the model configuration we will use for our tutorial \n%cat /kaggle/working/yolov5_depthwise_separable_conv/models/yolov5m.yaml","metadata":{"execution":{"iopub.status.busy":"2024-03-30T07:41:54.334968Z","iopub.execute_input":"2024-03-30T07:41:54.335326Z","iopub.status.idle":"2024-03-30T07:41:55.292051Z","shell.execute_reply.started":"2024-03-30T07:41:54.335293Z","shell.execute_reply":"2024-03-30T07:41:55.290977Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"# YOLOv5 🚀 by Ultralytics, AGPL-3.0 license\n\n# Parameters\nnc: 80 # number of classes\ndepth_multiple: 0.67 # model depth multiple\nwidth_multiple: 0.75 # layer channel multiple\nanchors:\n  - [10, 13, 16, 30, 33, 23] # P3/8\n  - [30, 61, 62, 45, 59, 119] # P4/16\n  - [116, 90, 156, 198, 373, 326] # P5/32\n\n# YOLOv5 v6.0 backbone\nbackbone:\n  # [from, number, module, args]\n  [\n    [-1, 1, Conv, [64, 6, 2, 2]], # 0-P1/2\n    [-1, 1, Conv, [128, 3, 2]], # 1-P2/4\n    [-1, 3, C3, [128]],\n    [-1, 1, Conv, [256, 3, 2]], # 3-P3/8\n    [-1, 6, C3, [256]],\n    [-1, 1, Conv, [512, 3, 2]], # 5-P4/16\n    [-1, 9, C3, [512]],\n    [-1, 1, Conv, [1024, 3, 2]], # 7-P5/32\n    [-1, 3, C3, [1024]],\n    [-1, 1, SPPF, [1024, 5]], # 9\n  ]\n\n# YOLOv5 v6.0 head\nhead: [\n    [-1, 1, Conv, [512, 1, 1]],\n    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n    [[-1, 6], 1, Concat, [1]], # cat backbone P4\n    [-1, 3, C3, [512, False]], # 13\n\n    [-1, 1, Conv, [256, 1, 1]],\n    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n    [[-1, 4], 1, Concat, [1]], # cat backbone P3\n    [-1, 3, C3, [256, False]], # 17 (P3/8-small)\n\n    [-1, 1, Conv, [256, 3, 2]],\n    [[-1, 14], 1, Concat, [1]], # cat head P4\n    [-1, 3, C3, [512, False]], # 20 (P4/16-medium)\n\n    [-1, 1, Conv, [512, 3, 2]],\n    [[-1, 10], 1, Concat, [1]], # cat head P5\n    [-1, 3, C3, [1024, False]], # 23 (P5/32-large)\n\n    [[17, 20, 23], 1, Detect, [nc, anchors]], # Detect(P3, P4, P5)\n  ]\n","output_type":"stream"}]},{"cell_type":"code","source":"#customize iPython writefile so we can write variables\nfrom IPython.core.magic import register_line_cell_magic\n\n@register_line_cell_magic\ndef writetemplate(line, cell):\n    with open(line, 'w') as f:\n        f.write(cell.format(**globals()))","metadata":{"execution":{"iopub.status.busy":"2024-03-30T07:41:55.294998Z","iopub.execute_input":"2024-03-30T07:41:55.295386Z","iopub.status.idle":"2024-03-30T07:41:55.300826Z","shell.execute_reply.started":"2024-03-30T07:41:55.295358Z","shell.execute_reply":"2024-03-30T07:41:55.299952Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"%%writetemplate /kaggle/working/yolov5_depthwise_separable_conv/models/custom_yolov5m.yaml\n\n# Parameters\nnc: {num_classes} # number of classes\ndepth_multiple: 0.67 # model depth multiple\nwidth_multiple: 0.75 # layer channel multiple\nanchors:\n  - [10, 13, 16, 30, 33, 23] # P3/8\n  - [30, 61, 62, 45, 59, 119] # P4/16\n  - [116, 90, 156, 198, 373, 326] # P5/32\n\n# YOLOv5 v6.0 backbone\nbackbone:\n  # [from, number, module, args]\n  [\n    [-1, 1, DepthwiseSeparableConv, [64, 6, 2, 2]], # 0-P1/2\n    [-1, 1, DepthwiseSeparableConv, [128, 3, 2]], # 1-P2/4\n    [-1, 3, C3, [128]],\n    [-1, 1, DepthwiseSeparableConv, [256, 3, 2]], # 3-P3/8\n    [-1, 6, C3, [256]],\n    [-1, 1, DepthwiseSeparableConv, [512, 3, 2]], # 5-P4/16\n    [-1, 9, C3, [512]],\n    [-1, 1, DepthwiseSeparableConv, [1024, 3, 2]], # 7-P5/32\n    [-1, 3, C3, [1024]],\n    [-1, 1, SPPF, [1024, 5]], # 9\n  ]\n\n# YOLOv5 v6.0 head\nhead: [\n    [-1, 1, DepthwiseSeparableConv, [512, 1, 1]],\n    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n    [[-1, 6], 1, Concat, [1]], # cat backbone P4\n    [-1, 3, C3, [512, False]], # 13\n\n    [-1, 1, DepthwiseSeparableConv, [256, 1, 1]],\n    [-1, 1, nn.Upsample, [None, 2, \"nearest\"]],\n    [[-1, 4], 1, Concat, [1]], # cat backbone P3\n    [-1, 3, C3, [256, False]], # 17 (P3/8-small)\n\n    [-1, 1, DepthwiseSeparableConv, [256, 3, 2]],\n    [[-1, 14], 1, Concat, [1]], # cat head P4\n    [-1, 3, C3, [512, False]], # 20 (P4/16-medium)\n\n    [-1, 1, DepthwiseSeparableConv, [512, 3, 2]],\n    [[-1, 10], 1, Concat, [1]], # cat head P5\n    [-1, 3, C3, [1024, False]], # 23 (P5/32-large)\n\n    [[17, 20, 23], 1, Detect, [nc, anchors]], # Detect(P3, P4, P5)\n  ]","metadata":{"execution":{"iopub.status.busy":"2024-03-30T07:41:55.302365Z","iopub.execute_input":"2024-03-30T07:41:55.302674Z","iopub.status.idle":"2024-03-30T07:41:55.311361Z","shell.execute_reply.started":"2024-03-30T07:41:55.302645Z","shell.execute_reply":"2024-03-30T07:41:55.310645Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"### export WANDB_MODE=disabled\n# train yolov5s on custom data for 100 epochs\n# time its performance\n%cd /kaggle/working/yolov5_depthwise_separable_conv/\n%time !python train.py --img 416 --batch 16 --epochs 25 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5m.yaml --weights '' --name yolov5s_results  --cache","metadata":{"execution":{"iopub.status.busy":"2024-03-30T07:41:55.312418Z","iopub.execute_input":"2024-03-30T07:41:55.312670Z","iopub.status.idle":"2024-03-30T09:28:06.347395Z","shell.execute_reply.started":"2024-03-30T07:41:55.312649Z","shell.execute_reply":"2024-03-30T09:28:06.346078Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/kaggle/working/yolov5_depthwise_separable_conv\n\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n2024-03-30 07:42:06.927189: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-30 07:42:06.927283: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-30 07:42:07.091025: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=./models/custom_yolov5m.yaml, data=/kaggle/working/yolov5_depthwise_separable_conv/thz-4/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=25, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\nremote: Enumerating objects: 3798, done.\u001b[K\nremote: Counting objects: 100% (3577/3577), done.\u001b[K\nremote: Compressing objects: 100% (1115/1115), done.\u001b[K\nremote: Total 3372 (delta 2562), reused 3042 (delta 2255), pack-reused 0\u001b[K\nReceiving objects: 100% (3372/3372), 426.42 KiB | 23.69 MiB/s, done.\nResolving deltas: 100% (2562/2562), completed with 68 local objects.\nFrom https://github.com/ultralytics/yolov5\n * [new branch]      add/weights_dir      -> ultralytics/add/weights_dir\n * [new branch]      benchmarks           -> ultralytics/benchmarks\n * [new branch]      exp/scaleFill        -> ultralytics/exp/scaleFill\n * [new branch]      exp12                -> ultralytics/exp12\n * [new branch]      exp13                -> ultralytics/exp13\n * [new branch]      exp13-nosoft         -> ultralytics/exp13-nosoft\n * [new branch]      exp13-soft           -> ultralytics/exp13-soft\n * [new branch]      fix/rgb_albumentations -> ultralytics/fix/rgb_albumentations\n * [new branch]      ghost                -> ultralytics/ghost\n * [new branch]      glenn-jocher-patch-1 -> ultralytics/glenn-jocher-patch-1\n * [new branch]      master               -> ultralytics/master\n * [new branch]      snyk-fix-9da5a0b0c0b87053afe81cdcfb84dde5 -> ultralytics/snyk-fix-9da5a0b0c0b87053afe81cdcfb84dde5\n * [new branch]      study_activations    -> ultralytics/study_activations\n * [new branch]      ultralytics/HUB      -> ultralytics/ultralytics/HUB\n * [new branch]      update/cls-album     -> ultralytics/update/cls-album\n * [new branch]      update/textlogger    -> ultralytics/update/textlogger\n * [new branch]      update/threaded      -> ultralytics/update/threaded\n * [new tag]         v1.0                 -> v1.0\n * [new tag]         v2.0                 -> v2.0\n * [new tag]         v3.0                 -> v3.0\n * [new tag]         v3.1                 -> v3.1\n * [new tag]         v4.0                 -> v4.0\n * [new tag]         v5.0                 -> v5.0\n * [new tag]         v6.0                 -> v6.0\n * [new tag]         v6.1                 -> v6.1\n * [new tag]         v6.2                 -> v6.2\n * [new tag]         v7.0                 -> v7.0\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\nWARNING ⚠️ invalid check_version(None, >=3.3) requested, please check values.\nYOLOv5 🚀 v7.0-306-gb2c0bf91 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\nDownloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 39.4MB/s]\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1       348  models.common.DepthwiseSeparableConv    [3, 48, 6, 2, 2]              \n  1                -1  1      5232  models.common.DepthwiseSeparableConv    [48, 96, 3, 2]                \n  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n  3                -1  1     19680  models.common.DepthwiseSeparableConv    [96, 192, 3, 2]               \n  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n  5                -1  1     76224  models.common.DepthwiseSeparableConv    [192, 384, 3, 2]              \n  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n  7                -1  1    299904  models.common.DepthwiseSeparableConv    [384, 768, 3, 2]              \n  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n 10                -1  1    296448  models.common.DepthwiseSeparableConv    [768, 384, 1, 1]              \n 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n 14                -1  1     74496  models.common.DepthwiseSeparableConv    [384, 192, 1, 1]              \n 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n 18                -1  1     38976  models.common.DepthwiseSeparableConv    [192, 192, 3, 2]              \n 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n 21                -1  1    151680  models.common.DepthwiseSeparableConv    [384, 384, 3, 2]              \n 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n 24      [17, 20, 23]  1    109107  models.yolo.Detect                      [22, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\ncustom_YOLOv5m summary: 301 layers, 16356063 parameters, 16356063 gradients\n\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 91 weight(decay=0.0005), 82 bias\nWARNING ⚠️ DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\nSee Multi-GPU Tutorial at https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training to get started.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov5_depthwise_separable_conv/thz-4/train/labe\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolov5_depthwise_separable_conv/thz-4/train/labels.cache\n\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (5.6GB ram): 100%|██████████| 11512/11512 [00:23<00:00, 49\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov5_depthwise_separable_conv/thz-4/valid/labels\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/yolov5_depthwise_separable_conv/thz-4/valid/labels.cache\n\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB ram): 100%|██████████| 722/722 [00:03<00:00, 228.20it\u001b[0m\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.49 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\nPlotting labels to runs/train/yolov5s_results/labels.jpg... \n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nImage sizes 416 train, 416 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/train/yolov5s_results\u001b[0m\nStarting training for 25 epochs...\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       0/24      1.69G    0.09432    0.01884    0.08145         10        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682   0.000494     0.0729    0.00035   6.07e-05\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       1/24         2G    0.06655    0.01626    0.06965         12        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.567      0.411      0.341      0.122\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       2/24         2G    0.05507     0.0128    0.05123         11        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.524      0.715      0.696      0.294\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       3/24         2G    0.05025    0.01159    0.03702         15        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.834      0.835      0.929      0.464\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       4/24         2G    0.04643    0.01091    0.02684         12        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.878      0.946      0.983      0.513\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       5/24         2G    0.04351     0.0105    0.02182         13        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.915      0.957      0.986      0.558\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       6/24         2G    0.04101   0.009967    0.01853         14        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682       0.97      0.979      0.991      0.566\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       7/24         2G    0.03929   0.009511    0.01619         10        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.964      0.986      0.994      0.608\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       8/24         2G    0.03763   0.009332    0.01465         14        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.983      0.994      0.992      0.622\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n       9/24         2G    0.03645   0.009213    0.01327         18        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.979      0.988      0.994      0.633\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      10/24         2G    0.03525   0.008975    0.01232         13        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682       0.98      0.993      0.995      0.639\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      11/24         2G    0.03419   0.008754    0.01126          9        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.986          1      0.995      0.652\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      12/24         2G    0.03365   0.008724    0.01095         10        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.995      0.999      0.995      0.671\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      13/24         2G    0.03283   0.008407    0.01012         13        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.988      0.998      0.995      0.676\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      14/24         2G    0.03196   0.008303   0.009037          8        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.987      0.993      0.995      0.675\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      15/24         2G    0.03134    0.00818   0.008545         15        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.989      0.999      0.995      0.679\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      16/24         2G    0.03066   0.008167   0.008095         13        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.987      0.999      0.995      0.686\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      17/24         2G    0.02989   0.007965   0.007927         16        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.994      0.995      0.995      0.694\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      18/24         2G    0.02939   0.007885   0.006991          7        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.993          1      0.995      0.691\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      19/24         2G    0.02872   0.007696   0.006457          9        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.993      0.998      0.995      0.703\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      20/24         2G    0.02814   0.007575   0.006169         11        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.993      0.999      0.995      0.709\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      21/24         2G    0.02754   0.007595   0.005974         12        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.992      0.999      0.995      0.711\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      22/24         2G    0.02679   0.007515   0.005227         17        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.992      0.999      0.995      0.721\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      23/24         2G    0.02631   0.007477   0.004976          9        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.992          1      0.995      0.722\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n      24/24         2G    0.02566   0.007352   0.004629         18        416: 1\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.993      0.999      0.995      0.727\n\n25 epochs completed in 1.738 hours.\nOptimizer stripped from runs/train/yolov5s_results/weights/last.pt, 33.1MB\nOptimizer stripped from runs/train/yolov5s_results/weights/best.pt, 33.1MB\n\nValidating runs/train/yolov5s_results/weights/best.pt...\nFusing layers... \ncustom_YOLOv5m summary: 231 layers, 16340319 parameters, 0 gradients\n                 Class     Images  Instances          P          R      mAP50   \n                   all        722        682      0.993      0.999      0.995      0.726\n               A4paper        722         33      0.993          1      0.995      0.835\n                    AK        722         19       0.99          1      0.995      0.846\n         AK_noMagazine        722         33      0.992          1      0.995      0.821\n                   M16        722         23      0.993          1      0.995      0.649\n                   axe        722         41      0.993          1      0.995      0.851\n           beltholster        722         39      0.995          1      0.995      0.749\n                bottle        722         31      0.994          1      0.995      0.737\n           candyboxLid        722         41      0.994          1      0.995      0.811\n          cigaretteBox        722         35      0.994          1      0.995      0.648\n                 fomka        722         32      0.989          1      0.995      0.675\n              glassjar        722         26      0.993          1      0.995      0.626\n       hammerAndSickle        722         18      0.988          1      0.995      0.697\n           handGranade        722         35      0.995          1      0.995      0.614\n                 knife        722         29      0.994          1      0.995      0.764\n             meatKnife        722         39      0.994          1      0.995      0.745\n            phoneNokia        722         33      0.995          1      0.995      0.709\n           phoneXiaomi        722         26      0.995          1      0.995      0.628\n                pistol        722         43      0.996          1      0.995      0.736\n           saucepanLid        722         27       0.99          1      0.995      0.794\n       shoulderholster        722         23       0.99          1      0.995      0.826\n                   tin        722         34      0.996          1      0.995      0.686\n               usbDisk        722         22          1      0.974      0.995      0.529\nResults saved to \u001b[1mruns/train/yolov5s_results\u001b[0m\nCPU times: user 1min 42s, sys: 19.2 s, total: 2min 2s\nWall time: 1h 46min 11s\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}